{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from collections import defaultdict\n",
    "from rouge import Rouge\n",
    "import spacy\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "nlp = spacy.load('zh_core_web_sm')\n",
    "import nltk\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate.nist_score import sentence_nist\n",
    "from bert_score import BERTScorer,score\n",
    "from sacrebleu.metrics import TER\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_scores(df, nlp):\n",
    "\n",
    "    embedding_avg_scores = {f'{col}-Embedding Average score': [] for col in ['1.5B-方法1', '1.5B-方法2', '7B-方法1','7B-方法2', '72B-方法1', '72B-方法2']}\n",
    "    for index, row in df.iterrows():\n",
    "        reference_embedding = np.mean([token.vector for token in nlp(row['标准答案'])], axis=0)\n",
    "        for col in ['1.5B-方法1', '1.5B-方法2','7B-方法1', '7B-方法2', '72B-方法1', '72B-方法2']:           \n",
    "            embedding_avg_similarity = cosine_similarity([reference_embedding], [candidate_embedding])[0][0]\n",
    "            embedding_avg_scores[f'{col}-Embedding Average score'].append(embedding_avg_similarity)\n",
    "    return embedding_avg_scores\n",
    "\n",
    "embedding_avg_scores = calculate_embedding_scores(data_2, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bert_scores(df):\n",
    "    bertscorer = BERTScorer(lang=\"zh\", rescale_with_baseline=True)\n",
    "    bert_scores.update({f'{col}-BERT': [] for col in ['1.5B-方法1', '1.5B-方法2','7B-方法1', '7B-方法2', '72B-方法1', '72B-方法2']})\n",
    "    for index, row in df.iterrows():\n",
    "        reference = row['标准答案']\n",
    "        for col in ['1.5B-方法1', '1.5B-方法2','7B-方法1', '7B-方法2', '72B-方法1', '72B-方法2']:\n",
    "            candidate = row[col]\n",
    "            P, R, F1 = bertscorer.score([candidate], [reference])\n",
    "            bert_scores[f'{col}-BERT召'].append(R.item())\n",
    "    return bert_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bert_scores(df):\n",
    "    bertscorer = BERTScorer(lang=\"zh\", rescale_with_baseline=True)\n",
    "    bert_scores = {\n",
    "        'AI答案-BERT': [],\n",
    "    }\n",
    "    for index, row in df.iterrows():\n",
    "        reference = row['标准答案'] \n",
    "        candidate = row['概率-原始输出']\n",
    "        _,R,_ = bertscorer.score([candidate], [reference])\n",
    "        bert_scores['AI答案-BERT'].append(R.item())\n",
    "    return bert_scores\n",
    "bert_scores = calculate_bert_scores(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_scores(df, nlp):\n",
    "    embedding_avg_scores = []\n",
    "    for index, row in df.iterrows():\n",
    "        reference_embedding = np.mean([token.vector for token in nlp(row['标准答案'])], axis=0)\n",
    "        candidate_embedding = np.mean([token.vector for token in nlp(row['概率-原始输出'])], axis=0)\n",
    "        embedding_avg_similarity = cosine_similarity([reference_embedding], [candidate_embedding])[0][0]\n",
    "        embedding_avg_scores.append(embedding_avg_similarity)\n",
    "    return embedding_avg_scores\n",
    "embedding_avg_scores = calculate_embedding_scores(data, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bert_scores(df):\n",
    "    bertscorer = BERTScorer(lang=\"zh\", rescale_with_baseline=True)\n",
    "    bert_scores = {\n",
    "        'AI答案-BERT': [],\n",
    "    }\n",
    "    for index, row in df.iterrows():\n",
    "        reference = row['标准答案'] \n",
    "        candidate = row['结果-LLM'] \n",
    "        _, R, _ = bertscorer.score([candidate], [reference])\n",
    "        bert_scores['AI答案-BERT'].append(R.item())\n",
    "    return bert_scores\n",
    "bert_scores = calculate_bert_scores(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_scores(df, nlp):\n",
    "    embedding_avg_scores = []\n",
    "    for index, row in df.iterrows():\n",
    "        reference_embedding = np.mean([token.vector for token in nlp(row['标准答案'])], axis=0)\n",
    "        candidate_embedding = np.mean([token.vector for token in nlp(row['结果-LLM'])], axis=0)\n",
    "        embedding_avg_similarity = cosine_similarity([reference_embedding], [candidate_embedding])[0][0]\n",
    "        embedding_avg_scores.append(embedding_avg_similarity)\n",
    "    return embedding_avg_scores\n",
    "embedding_avg_scores = calculate_embedding_scores(data, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"***\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "results = []\n",
    "for index, row in data.iterrows():\n",
    "    question = row['问题']\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"qwen3-32b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"作为消化科医生，请用精简的中文回答，不要透露AI身份。直接给出结论，不要重复问题。请严格地以连续的自然段形式作答，不要分条列举。输出生成的内容前，请仔细检查文本内容，禁止使用###、##、#、***、**、*、 这样的格式标记内容，禁止重点标记、标题、空格。禁止回复答案来源，例如‘根据xxx研究’、‘根据搜索材料’、‘根据提供的信息’、‘基于提供的资料’之类的话术\"\n",
    "            }},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            extra_body={\"enable_thinking\": False},\n",
    "        )\n",
    "        results.append(completion.model_dump_json())\n",
    "    except Exception as e:\n",
    "        results.append(f\"Error processing question {question}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies = []\n",
    "for result in results:\n",
    "    try:\n",
    "        data = json.loads(result)\n",
    "        reply = data['choices'][0]['message']['content']\n",
    "        replies.append(reply)\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing result: {e}\")\n",
    "        replies.append(\"Error extracting content\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
