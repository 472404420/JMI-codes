{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "import logging\n",
    "import time\n",
    "import spacy\n",
    "import jieba\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import fitz\n",
    "import faiss\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "# headers = {\n",
    "#     \"Authorization\": \"Bearer ***\",\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "def get_llm_response(question):\n",
    "    payload = {\n",
    "        \"model\": \"Qwen/Qwen2-72B-Instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":  f\"作为消化科医生，请用精简的中文回答，不要透露AI身份。直接给出结论，不要重复问题。请严格地以连续的自然段形式作答，不要分条列举。输出生成的内容前，请仔细检查文本内容，禁止使用###、##、#、***、**、*、 这样的格式标记内容，禁止重点标记、标题、空格。禁止回复答案来源，例如‘根据xxx研究’、‘根据搜索材料’、‘根据提供的信息’、‘基于提供的资料’之类的话术：{question}\"\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\":800 ,\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 5,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"n\": 1,\n",
    "        \"response_format\": {\"type\": \"text\"}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            print(f\"请求失败，状态码：{response.status_code}\")\n",
    "            return \"请求失败\"\n",
    "    except Exception as e:\n",
    "        print(f\"请求发生错误：{e}\")\n",
    "        return \"请求失败\"\n",
    "\n",
    "model = SentenceTransformer('D:/python/BERTopic/all_MiniLM_L6_v2')\n",
    "\n",
    "def sliding_window(text, window_size=20, step_size=15):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences) - window_size + 1, step_size):\n",
    "        chunk = ' '.join(sentences[i:i + window_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def process_chunks(chunks):\n",
    "    try:\n",
    "        embeddings = model.encode(chunks, batch_size=8) \n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunks: {e}\")\n",
    "        return None\n",
    "    \n",
    "documents = sliding_window(text)\n",
    "results = []\n",
    "batch_size = 8 \n",
    "batches = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "for batch in batches:\n",
    "    result = process_chunks(batch)\n",
    "    results.append(result)\n",
    "\n",
    "embeddings = np.concatenate(results, axis=0)\n",
    "\n",
    "model = SentenceTransformer('D:/python/BERTopic/all_MiniLM_L6_v2')\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1]) \n",
    "index.add(np.array(embeddings, dtype=np.float32)) \n",
    "\n",
    "def get_llm_response(question, context):\n",
    "    payload = {\n",
    "        \"model\": \"Qwen/Qwen2-72B-Instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":  f\"作为消化科医生，请用精简的中文回答，不要透露AI身份。直接给出结论，不要重复问题。请严格地以连续的自然段形式作答，不要分条列举。输出生成的内容前，请仔细检查文本内容，禁止使用###、##、#、***、**、*、 这样的格式标记内容，禁止重点标记、标题、空格。禁止回复答案来源，例如‘根据xxx研究’、‘根据搜索材料’、‘根据提供的信息’、‘基于提供的资料’之类的话术。患者问题：{question}。\\\n",
    "                    参考内容不一定与问题完全相关，若参考内容对问题没有贡献，可以考虑无视。如果参考部分内容，请流畅地把相关内容加入到你的回答中，参考信息如下：{context}。\"\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": 800,\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 5,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"n\": 1,\n",
    "        \"response_format\": {\"type\": \"text\"}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            print(f\"请求失败，状态码：{response.status_code}\")\n",
    "            return \"请求失败\"\n",
    "    except Exception as e:\n",
    "        print(f\"请求发生错误：{e}\")\n",
    "        return \"请求失败\"\n",
    "    \n",
    "def get_top_5_answers(question):\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "      \"q\": question\n",
    "    })\n",
    "    headers = {\n",
    "      'X-API-KEY': '***',\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()        \n",
    "        organic_results = data.get('organic', [])\n",
    "        top_5_answers = []\n",
    "        for result in organic_results[:5]:\n",
    "            snippet = result.get('snippet', 'No Snippet Available')\n",
    "            top_5_answers.append(snippet)\n",
    "        return top_5_answers\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "def process_question(question):\n",
    "    query_embedding = model.encode([question])\n",
    "    k = 5  \n",
    "    distances, indices = index.search(np.array(query_embedding, dtype=np.float32), k)\n",
    "    context = \" \".join([documents[idx] for idx in indices[0]])\n",
    "    serper_result = get_top_5_answers(question)\n",
    "    serper_result = \"。\".join(serper_result)\n",
    "    context += f\" {serper_result}\"\n",
    "    answer = get_llm_response_with_formatting(question, context)\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
